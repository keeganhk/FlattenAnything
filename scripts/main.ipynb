{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a499e13-bf46-45fa-b1f6-17e6829bef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from cdbs.funcs import *\n",
    "from cdbs.network import FlattenAnythingModel\n",
    "data_root = \"../data\"\n",
    "expt_root = \"../expt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc4cd8-33f9-4b5d-b3c8-20c7b2c6fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"open__human-hand\"\n",
    "cfg_name = \"experiment-01\"\n",
    "\n",
    "save_folder = os.path.join(expt_root, model_name + \"__\" + cfg_name)\n",
    "if os.path.exists(save_folder):\n",
    "    shutil.rmtree(save_folder)\n",
    "os.mkdir(save_folder)\n",
    "log_file = os.path.join(save_folder, \"log.txt\")\n",
    "if os.path.exists(log_file):\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef2e6b-3730-4c47-9043-936acfdc72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FlattenAnythingModel().train().cuda()\n",
    "max_lr, min_lr, num_epc, opt_diff_itv = 1e-3, 1e-5, 10000, 5\n",
    "optimizer = optim.AdamW(net.parameters(), lr=max_lr, weight_decay=1e-8)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epc, eta_min=min_lr)\n",
    "L1Loss, L2Loss = nn.L1Loss(), nn.MSELoss()\n",
    "write_log_itv = (num_epc // 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecaeb56-fd8a-4a42-a44b-24d7b618f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_v, mesh_vn, mesh_f = load_mesh_model_vfn(os.path.join(data_root, \"input_meshes\", model_name + \".obj\"))\n",
    "pre_samplings = np.loadtxt(os.path.join(data_root, \"sampled_points\", model_name + \".txt\"), dtype=\"float32\", delimiter=\";\") # (num_pts_pres, 6)\n",
    "num_pts_pres = pre_samplings.shape[0]\n",
    "pre_samplings[:, 3:6] = rescale_normals(pre_samplings[:, 3:6], scale=1.0)\n",
    "pre_samplings = torch.tensor(pre_samplings).unsqueeze(0).float().cuda() # [1, num_pts_pres, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b48a6-d5f2-4ad8-87ae-f8366104958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000 # number of input 3D points at each training iteration\n",
    "grid_height, grid_width = int(np.sqrt(N)), int(np.sqrt(N))\n",
    "G = torch.tensor(build_2d_grids(grid_height, grid_width).reshape(-1, 2)).unsqueeze(0).float().cuda() # [1, M, 2]\n",
    "M = G.size(1) # number of grid 2D points\n",
    "\n",
    "num_col_samp = 20\n",
    "collected_samplings = []\n",
    "for i in tqdm(range(num_col_samp)):\n",
    "    sampling_base = pre_samplings[:, np.random.choice(num_pts_pres, 100000, replace=False), :]\n",
    "    collected_samplings.append(index_points(sampling_base, get_fps_idx(sampling_base[:, :, 0:3], N)))\n",
    "collected_samplings = torch.cat(collected_samplings, dim=0) # [num_col_samp, N, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc251f-dcaf-4f5d-b23a-304e11e11250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epc_idx in tqdm(range(1, num_epc+1)):\n",
    "    net.zero_grad()\n",
    "    np.random.seed()\n",
    "    input_pc = collected_samplings[np.random.choice(num_col_samp), ...].unsqueeze(0) # [1, N, 6]\n",
    "    P = input_pc[:, :, 0:3] # [1, N, 3], point coordinates at this training iteration\n",
    "    P_gtn = input_pc[:, :, 3:6] # [1, N, 3], ground-truth point normals at this training iteration\n",
    "    \n",
    "    #### forward pass\n",
    "    P_opened, Q, P_cycle, P_cycle_n, Q_hat, P_hat, P_hat_n, P_hat_opened, Q_hat_cycle = net(G, P)\n",
    "    Q_normalized = uv_bounding_box_normalization(Q)\n",
    "    Q_hat_normalized = uv_bounding_box_normalization(Q_hat)\n",
    "    Q_hat_cycle_normalized = uv_bounding_box_normalization(Q_hat_cycle)\n",
    "\n",
    "    #### wrapping loss\n",
    "    L_wrap = chamfer_distance_cuda(P_hat, P)\n",
    "\n",
    "    #### unwrapping loss\n",
    "    rep_th = (2 / (np.ceil(np.sqrt(M)) - 1)) * 0.25\n",
    "    L_unwrap = compute_repulsion_loss(Q_normalized, 8, rep_th) + compute_repulsion_loss(Q_hat_normalized, 8, rep_th) + compute_repulsion_loss(Q_hat_cycle_normalized, 8, rep_th)\n",
    "\n",
    "    #### cycle consistency on points\n",
    "    L_cc_p = L1Loss(P, P_cycle) + L1Loss(Q_hat, Q_hat_cycle)\n",
    "    \n",
    "    #### cycle consistency on normals\n",
    "    L_cc_n = compute_normal_cos_sim_loss(P_gtn, P_cycle_n)\n",
    "\n",
    "    '''\n",
    "    #### cutting offset bound loss\n",
    "    # concat_P_opened = torch.cat(P_opened, dim=0) # [num_cuts, N, 3]\n",
    "    # offset_lengths = ((concat_P_opened ** 2).sum(dim=-1) + 1e-8).sqrt() # [num_cuts, N]\n",
    "    # max_offset_len = 0.25\n",
    "    # L_cob = F.relu(offset_lengths - max_offset_len).mean()\n",
    "    '''\n",
    "    \n",
    "    #### overall loss function\n",
    "    if epc_idx==1 or np.mod(epc_idx, opt_diff_itv) == 0:\n",
    "        _, e1, e2 = compute_differential_properties(P_cycle, Q)\n",
    "        L_conf = L1Loss(e1, e2)\n",
    "        L_isom = (e1 - 1).abs().mean() + (e2 - 1).abs().mean()\n",
    "        loss = L_wrap + L_unwrap*0.01 + L_cc_p*0.01 + L_cc_n*0.005 + L_conf*0.01 # + L_cob*0.005\n",
    "    else:\n",
    "        loss = L_wrap + L_unwrap*0.01 + L_cc_p*0.01 + L_cc_n*0.005 # + L_cob*0.005\n",
    "    \n",
    "    curr_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if np.mod(epc_idx, write_log_itv) == 0:\n",
    "        info = {}\n",
    "        write_to = \"\"\n",
    "        info[\"epoch\"] = align_number(epc_idx, 6)\n",
    "        info[\"L_wrap\"] = \"%.6f\" % L_wrap.item()\n",
    "        info[\"L_unwrap\"] = \"%.6f\" % L_unwrap.item()\n",
    "        info[\"L_cc_p\"] = \"%.6f\" % L_cc_p.item()\n",
    "        info[\"L_cc_n\"] = \"%.6f\" % L_cc_n.item()\n",
    "        # info[\"L_cob\"] = \"%.6f\" % L_cob.item()\n",
    "        info[\"L_conf\"] = \"%.6f\" % L_conf.item()\n",
    "        info[\"L_isom\"] = \"%.6f\" % L_isom.item()\n",
    "        for info_k, info_v in info.items():\n",
    "            write_to += info_k + \": \" + info_v + \" \"\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.writelines(write_to + \"\\n\")\n",
    "        \n",
    "        plt.figure(figsize=(2.5, 2.5))\n",
    "        plt.axis('off')\n",
    "        plt.scatter(ts2np(Q_hat_normalized.squeeze(0))[:, 0], ts2np(Q_hat_normalized.squeeze(0))[:, 1], s=0.2, c=\"r\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(2.5, 2.5))\n",
    "        plt.axis('off')\n",
    "        plt.scatter(ts2np(Q_hat_cycle_normalized.squeeze(0))[:, 0], ts2np(Q_hat_cycle_normalized.squeeze(0))[:, 1], s=0.2, c=\"g\")\n",
    "        plt.show()\n",
    "    \n",
    "        plt.figure(figsize=(2.5, 2.5))\n",
    "        plt.axis('off')\n",
    "        plt.scatter(ts2np(Q_normalized.squeeze(0))[:, 0], ts2np(Q_normalized.squeeze(0))[:, 1], s=0.2, c=((ts2np(P_gtn.squeeze(0)) + 1) / 2))\n",
    "        plt.show()\n",
    "\n",
    "net.zero_grad()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#### save network parameters and outputs\n",
    "torch.save(net.state_dict(), os.path.join(save_folder, \"fam.pth\"))\n",
    "\n",
    "P_cycle_n = F.normalize(P_cycle_n, dim=-1)\n",
    "P_hat_n = F.normalize(P_hat_n, dim=-1)\n",
    "save_pc_as_ply(os.path.join(save_folder, \"last_epoch__input_pc.ply\"), input_pc[0, :, 0:3], normals=input_pc[0, :, 3:6]*0.15)\n",
    "save_pc_as_ply(os.path.join(save_folder, \"last_epoch__P_cycle_with_n.ply\"), P_cycle[0], normals=P_cycle_n[0]*0.15)\n",
    "save_pc_as_ply(os.path.join(save_folder, \"last_epoch__P_hat_with_n.ply\"), P_hat[0], normals=P_hat_n[0]*0.15)\n",
    "save_pc_as_ply(os.path.join(save_folder, \"last_epoch__P_opened.ply\"), P_opened.squeeze(0))\n",
    "save_pc_as_ply(os.path.join(save_folder, \"last_epoch__P_hat_opened.ply\"), P_hat_opened.squeeze(0))\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.axis('off')\n",
    "plt.scatter(ts2np(Q_hat_normalized.squeeze(0))[:, 0], ts2np(Q_hat_normalized.squeeze(0))[:, 1], s=2.0, c=\"r\")\n",
    "plt.savefig(os.path.join(save_folder, \"Q_hat_normalized.png\"), dpi=400, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.axis('off')\n",
    "plt.scatter(ts2np(Q_hat_cycle_normalized.squeeze(0))[:, 0], ts2np(Q_hat_cycle_normalized.squeeze(0))[:, 1], s=2.0, c=\"g\")\n",
    "plt.savefig(os.path.join(save_folder, \"Q_hat_cycle_normalized.png\"), dpi=400, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.axis('off')\n",
    "plt.scatter(ts2np(Q_normalized.squeeze(0))[:, 0], ts2np(Q_normalized.squeeze(0))[:, 1], s=2.0, c=((ts2np(P_gtn.squeeze(0)) + 1) / 2))\n",
    "plt.savefig(os.path.join(save_folder, \"Q_normalized.png\"), dpi=400, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146476eb-87a6-4d8f-b801-d5f248959d8e",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e495c-d191-4351-861d-d1ef31950aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_pc_eval = pre_samplings # [1, num_pts_pres, 6]\n",
    "P_eval = input_pc_eval[:, :, 0:3] # [1, num_pts_pres, 3]\n",
    "P_gtn_eval = input_pc_eval[:, :, 3:6] # [1, num_pts_pres, 3]\n",
    "grid_height_eval, grid_width_eval = int(np.sqrt(num_pts_pres)), int(np.sqrt(num_pts_pres))\n",
    "G_eval = torch.tensor(build_2d_grids(grid_height_eval, grid_width_eval).reshape(-1, 2)).unsqueeze(0).float().cuda() # [1, M_eval, 2]\n",
    "M_eval = G_eval.size(1)\n",
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():\n",
    "    P_opened_eval, Q_eval, P_cycle_eval, P_cycle_n_eval, Q_hat_eval, P_hat_eval, P_hat_n_eval, P_hat_opened_eval, Q_hat_cycle_eval = net(G_eval, P_eval)\n",
    "Q_eval_normalized = uv_bounding_box_normalization(Q_eval)\n",
    "Q_hat_eval_normalized = uv_bounding_box_normalization(Q_hat_eval)\n",
    "Q_hat_cycle_eval_normalized = uv_bounding_box_normalization(Q_hat_cycle_eval)\n",
    "\n",
    "P_cycle_n_eval = F.normalize(P_cycle_n_eval, dim=-1) # [1, num_pts_pres, 3]\n",
    "P_hat_n_eval = F.normalize(P_hat_n_eval, dim=-1) # [1, num_pts_pres, 3]\n",
    "save_pc_as_ply(os.path.join(save_folder, \"P_cycle_eval_with_n.ply\"), P_cycle_eval[0], normals=P_cycle_n_eval[0]*0.15)\n",
    "save_pc_as_ply(os.path.join(save_folder, \"P_hat_eval_with_n.ply\"), P_hat_eval[0], normals=P_hat_n_eval[0]*0.15)\n",
    "\n",
    "save_pc_as_ply(os.path.join(save_folder, \"P_opened_eval.ply\"), P_opened_eval.squeeze(0))\n",
    "save_pc_as_ply(os.path.join(save_folder, \"P_hat_opened_eval.ply\"), P_hat_opened_eval.squeeze(0))\n",
    "\n",
    "is_edge_threshold = 0.02 # smaller threshold -> more edge points\n",
    "edge_mask_eval = extract_edge_points(P_eval, Q_eval_normalized, 1, is_edge_threshold) # [num_pts_pres]\n",
    "if edge_mask_eval.sum().item() == 0:\n",
    "    print('no edge found yet.')\n",
    "else:\n",
    "    P_eval_edge = P_eval[:, edge_mask_eval, :] # [1, num_pts_eval_edge, 3]\n",
    "    num_pts_eval_edge = P_eval_edge.size(1)\n",
    "    print('[{}] points judged to be on edges.'.format(num_pts_eval_edge))\n",
    "    save_pc_as_ply(os.path.join(save_folder, \"P_eval_edge.ply\"), P_eval_edge.squeeze(0))\n",
    "\n",
    "tex_img_path = os.path.join(data_root, \"texture_images\", \"checker_maps\", 'v1_r3.png')\n",
    "tex_img_resolution = 1024\n",
    "texture_uv, texture_rgb = load_texture_map(tex_img_path, tex_img_resolution, binarize=True)\n",
    "texture_uv = torch.tensor(texture_uv).unsqueeze(0).float().cuda() # [1, tex_img_resolution**2, 3]\n",
    "texture_rgb = torch.tensor(texture_rgb).unsqueeze(0).float().cuda() # [1, tex_img_resolution**2, 3]\n",
    "matched_rgb = index_points(texture_rgb, knn_search(texture_uv, Q_eval_normalized, 1).squeeze(-1)) # [1, num_pts_pres, 3]\n",
    "P_eval_textured = torch.cat((P_eval, matched_rgb), dim=-1) # [1, num_pts_pres, 6]\n",
    "save_pc_as_ply(os.path.join(save_folder, \"P_eval_textured_with_n.ply\"), P_eval_textured[0, :, 0:3], colors=P_eval_textured[0, :, 3:6], normals=P_gtn_eval[0]*0.15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
